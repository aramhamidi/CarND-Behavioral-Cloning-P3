{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "after copying and extracting the data on EC2 instance We want read the data for each line extratc the path to the camera image path\n",
    "but we need to update the path cause it's not on out local machin\n",
    "anymore, and it's on the AWS instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# easy way to update the path\n",
    "Split the path on it's slashes and then extract the final token\n",
    "which will be file name.\n",
    "then we can add that file name to the end of the image directory\n",
    "here on the AWS instance.\n",
    "Now that we have the current path we can use opencv to load the image\n",
    "and append it to the our list of images\n",
    "we can do the same thing for the steering measurements, which will serve \n",
    "as our output labels, but with this difference that there would be no path\n",
    "or no images to handle, just simply extract the 4th token from the csv line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data is loaded\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "lines = []\n",
    "with open ('data/driving_log.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for line in reader:\n",
    "        lines.append(line)\n",
    "del(lines[0])        \n",
    "images = []\n",
    "measurements = []\n",
    "augmented_images, augmented_measurements = [], []\n",
    "\n",
    "for line in lines:    \n",
    "        source_path = line[0]\n",
    "        filename = source_path.split('/')[-1]\n",
    "        current_path = 'data/IMG/' + filename\n",
    "        image = cv2.imread(current_path)\n",
    "        if image is None:\n",
    "            print(\"Image path incorrect: \", current_path)\n",
    "        images.append(image)\n",
    "        measurement = float(line[3])\n",
    "        measurements.append(measurement)\n",
    "\n",
    "for image, measurement in zip(images, measurements):\n",
    "    augmented_images.append(image)\n",
    "    augmented_measurements.append(measurement)\n",
    "    augmented_images.append(cv2.flip(image,1))\n",
    "    augmented_measurements.append(measurement * -1.0)\n",
    "# Now we need to format them in numpy arrays cause that's Keras requirment\n",
    "X_train = np.array(augmented_images)\n",
    "y_train = np.array(augmented_measurements)\n",
    "        \n",
    "print(\"Data is loaded\")        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Basic Model\n",
    "Now we are going to build the most basic NW possible\n",
    "Just to verify that everthing is working fine.\n",
    "This NW is going to be a flattened image connected to a\n",
    "single output node. This single output node is going to predict \n",
    "the steering angle, which makes this a regression network.\n",
    "\n",
    "For a Classification Netwrok we might need to apply a softmax activation function to the output layer. But for a regression network like this we just need a single output node to directly predict the steering angle for us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default Keras trains for 10 epochs. But we can see the validation loss decreases for the first 7 epochs and then it starts to climbing again.\n",
    "This is a sign that maybe we are over fitting the data. The validation loss should decrease for almost all the epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12857 samples, validate on 3215 samples\n",
      "Epoch 1/5\n",
      "12857/12857 [==============================] - 28s - loss: 0.0869 - val_loss: 0.0126\n",
      "Epoch 2/5\n",
      "12857/12857 [==============================] - 23s - loss: 0.0105 - val_loss: 0.0110\n",
      "Epoch 3/5\n",
      "12857/12857 [==============================] - 24s - loss: 0.0097 - val_loss: 0.0108\n",
      "Epoch 4/5\n",
      "12857/12857 [==============================] - 23s - loss: 0.0094 - val_loss: 0.0111\n",
      "Epoch 5/5\n",
      "12857/12857 [==============================] - 23s - loss: 0.0090 - val_loss: 0.0112\n",
      "model saved!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Lambda\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers import Cropping2D\n",
    "import cv2\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Lambda(lambda x: (x / 255.0) - 0.5, input_shape=(160, 320,3)))\n",
    "model.add(Cropping2D(cropping=((70,25),(0,0))))\n",
    "model.add(Convolution2D(6,5,5, activation=\"relu\"))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Convolution2D(6,5,5,activation =\"relu\"))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(120))\n",
    "model.add(Dense(84))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# For the loss function we use mean square , or MSE, which is differnt\n",
    "# than cross_entropy function, again becuase this is a regression network \n",
    "# not a classifer network.\n",
    "\n",
    "# We want to minimize the error between the stearing measurementss that the \n",
    "# Network predicts and the ground truth steering measurement.\n",
    "# MSE is good loss function for this.\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "# Once the model is compiled we'll train the feature and label arrays\n",
    "# we just build.\n",
    "# WE also shuffle the data and also split off 20% of the data to use \n",
    "# for validation set.\n",
    "\n",
    "model.fit(X_train, y_train, validation_split=0.2, shuffle=True, nb_epoch=5)\n",
    "\n",
    "# Now we will save the model and download it onto our local machine,\n",
    "# and see if it works for driving the simulator.\n",
    "\n",
    "model.save('LeNetmodel.h5')\n",
    "print(\"model saved!\")\n",
    "exit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step is to download this model toour local machine."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
